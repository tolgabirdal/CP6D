{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from IPython import embed\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# compute the relative pose\n",
    "def normalize_vector( v):\n",
    "    batch=v.shape[0]\n",
    "    v_mag = torch.sqrt(v.pow(2).sum(1))# batch\n",
    "    v_mag = torch.max(v_mag, torch.autograd.Variable(torch.FloatTensor([1e-8])))\n",
    "    v_mag = v_mag.view(batch,1).expand(batch,v.shape[1])\n",
    "    v = v/v_mag\n",
    "    return v\n",
    "\n",
    "def compute_quaternions_from_rotation_matrices(matrices):\n",
    "    batch=matrices.shape[0]\n",
    "    \n",
    "    w=torch.sqrt(torch.max(1.0 + matrices[:,0,0] + matrices[:,1,1] + matrices[:,2,2], torch.zeros(1))) / 2.0\n",
    "    w = torch.max (w , torch.autograd.Variable(torch.zeros(batch))+1e-8) #batch\n",
    "    w4 = 4.0 * w\n",
    "    x= (matrices[:,2,1] - matrices[:,1,2]) / w4\n",
    "    y= (matrices[:,0,2] - matrices[:,2,0]) / w4\n",
    "    z= (matrices[:,1,0] - matrices[:,0,1]) / w4\n",
    "    quats = torch.cat((w.view(batch,1), x.view(batch, 1),y.view(batch, 1), z.view(batch, 1) ), 1   )\n",
    "    quats = normalize_vector(quats)\n",
    "    return quats\n",
    "\n",
    "def compute_rotation_matrix_from_quaternion( quaternion, n_flag=True):\n",
    "    batch=quaternion.shape[0]\n",
    "    if n_flag:\n",
    "        quat = normalize_vector(quaternion)\n",
    "    else:\n",
    "        quat = quaternion\n",
    "    qw = quat[...,0].view(batch, 1)\n",
    "    qx = quat[...,1].view(batch, 1)\n",
    "    qy = quat[...,2].view(batch, 1)\n",
    "    qz = quat[...,3].view(batch, 1)\n",
    "\n",
    "    # Unit quaternion rotation matrices computatation  \n",
    "    xx = qx*qx\n",
    "    yy = qy*qy\n",
    "    zz = qz*qz\n",
    "    xy = qx*qy\n",
    "    xz = qx*qz\n",
    "    yz = qy*qz\n",
    "    xw = qx*qw\n",
    "    yw = qy*qw\n",
    "    zw = qz*qw\n",
    "\n",
    "    row0 = torch.cat((1-2*yy-2*zz, 2*xy - 2*zw, 2*xz + 2*yw), 1) #batch*3\n",
    "    row1 = torch.cat((2*xy+ 2*zw,  1-2*xx-2*zz, 2*yz-2*xw  ), 1) #batch*3\n",
    "    row2 = torch.cat((2*xz-2*yw,   2*yz+2*xw,   1-2*xx-2*yy), 1) #batch*3\n",
    "    \n",
    "    matrix = torch.cat((row0.view(batch, 1, 3), row1.view(batch,1,3), row2.view(batch,1,3)),1) #batch*3*3\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def rot_err_q(est_pose, gt_pose):\n",
    "                 \n",
    "    est_pose_q = F.normalize(est_pose, p=2, dim=1)\n",
    "    gt_pose_q = F.normalize(gt_pose, p=2, dim=1)\n",
    "    inner_prod = torch.bmm(est_pose_q.view(est_pose_q.shape[0], 1, est_pose_q.shape[1]),\n",
    "                           gt_pose_q.view(gt_pose_q.shape[0], gt_pose_q.shape[1], 1)) \n",
    "    # if torch.abs(inner_prod) <= 1:\n",
    "    orient_err = 2 * torch.acos(torch.abs(inner_prod)) * 180 / torch.pi\n",
    "    # else:\n",
    "    #     origin = torch.abs(torch.abs(inner_prod) - int(torch.abs(inner_prod)) - 1)\n",
    "    #     orient_err = 2 * torch.acos(origin) * 180 / torch.pi\n",
    "    return orient_err\n",
    "\n",
    "def rot_err_R(est_pose, gt_pose):\n",
    "    est_R = compute_rotation_matrix_from_quaternion(est_pose)\n",
    "    gt_R = compute_quaternions_from_rotation_matrices(gt_pose)\n",
    "    rot = torch.matmul(est_R.transpose(1, 2), gt_R)\n",
    "    U, S, Vh = torch.linalg.svd(rot)\n",
    "    V = Vh.mH\n",
    "    log_rot = U @ torch.diag(torch.log(S)) @ V\n",
    "    rot_err = torch.mean(torch.abs(log_rot)) / torch.pi\n",
    "    return rot_err\n",
    "\n",
    "def translation_err(est_pose, gt_pose):\n",
    "    \"\"\"\n",
    "    Calculate the position error given the estimated and ground truth pose(s).\n",
    "    :param est_pose: (torch.Tensor) a batch of estimated poses (Nx7, N is the batch size)\n",
    "    :param gt_pose: (torch.Tensor) a batch of ground-truth poses (Nx7, N is the batch size)\n",
    "    :return: position error(s)\n",
    "    \"\"\"\n",
    "    posit_err = torch.norm(est_pose[:, 0:3] - gt_pose[:, 0:3], dim=1)\n",
    "    return posit_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_gt = torch.tensor([[-0.0086188981315046,0.9658827547330426,8.32611692498036,0.9971564052053462,0.0562843980563516,-0.0499919500231132,-0.0034604950906209]])\n",
    "pose_est = torch.tensor([[0.04115517437458038,0.9318070411682129,8.151130676269531,0.9971417784690857,0.05427778884768486,-0.052424173802137375,-0.0037253866903483868]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CP6D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
